---
layout: post
title: "Hadoop（一）Hadoop环境搭建"
subtitle: '大数据学习起步之分布式存储  HDFS'
author: "Oumuv"
date:   2018-12-18 12:00:00
header-img:   "img/about-bg.jpg"
header-mask:  0.3
catalog:      true
tags:
  - Hadoop
---

# 环境要求
* JDK8
* Hadoop2.6

# 步骤
## 一、下载
点击 [Hadoop下载](http://mirror.cc.columbia.edu/pub/software/apache/hadoop/common/)
## 二、安装Hadoop
安装Hadoop之前先确保JDK已经安装好   

新建一个名为hadoop的目录将安装包解压到该目录下
> mkdir hadoop   
> tar -zxvf hadoop-2.6.5.tar.gz

## 三、配置环境变量
编辑/etc/profile,加入如下配置：

```
export HADOOP_HOME=/root/hadoop/hadoop-2.6.5   
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```
刷新一下
> source /etc/profile

输入hadoop version测试是否生效：   
![在这里插入图片描述](https://raw.githubusercontent.com/Oumuv/oumuv.git.res/master/resources/img/2018/12/20/01.png)

## 四、配置文件
* 配置 /hadoop-2.6.5/etc/hadoop/core-site.xml
```
<configuration>
<!-- 配置地址与端口-->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://centos:9000</value>
    </property>
<!-- 配置数据存放路径-->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/hadoop/hadoopData</value>
    </property>
</configuration>
```
* 配置/hadoop-2.6.5/etc/hadoop/hdfs-site.xml
```
<configuration>
<!-- 配置副本数为1，如果不配置默认是3-->
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>
```
## 五、启动、测试
### 启动hdfs步骤：
* 启动之前需要先格式化hdfs（这一步操作一般是用于第一次启动hdfs时候初始化，只需操作一次以后都不用在操作）
> hadoop namenode -format   

![在这里插入图片描述](https://raw.githubusercontent.com/Oumuv/oumuv.git.res/master/resources/img/2018/12/20/02.png)

* 启动hdfs
> start-dfs.sh

![在这里插入图片描述](https://raw.githubusercontent.com/Oumuv/oumuv.git.res/master/resources/img/2018/12/20/03.png)
这一条命令执行后将会要求输入3次密码，分别启动一个SecondaryNameNode、NameNode、DataNode

* 使用浏览器访问 http://localhost:50070/ 将会看见如下界面   
![在这里插入图片描述](https://raw.githubusercontent.com/Oumuv/oumuv.git.res/master/resources/img/2018/12/20/04.png)

* stop-dfs.sh停止hdfs
> stop-dfs.sh
# 搭建完成
